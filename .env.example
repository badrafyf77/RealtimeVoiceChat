# Voice Chat Configuration
# Copy this to .env and configure your settings

# ============================================
# OPTION 1: Bedrock Agent (AWS Managed LLM) - DEFAULT
# ============================================
LLM_PROVIDER=bedrock
BEDROCK_AGENT_ID=YOUR_AGENT_ID
BEDROCK_AGENT_ALIAS_ID=YOUR_ALIAS_ID
BEDROCK_REGION=us-west-2

# AWS Credentials (required for Bedrock)
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
# AWS_SESSION_TOKEN=your_session_token  # Optional, for temporary credentials
AWS_REGION=us-west-2

# ============================================
# OPTION 2: Ollama (Local LLM)
# ============================================
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2:latest
# OLLAMA_BASE_URL=http://ollama:11434  # Set in docker-compose.yml

# ============================================
# OPTION 3: OpenAI
# ============================================
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4
# OPENAI_API_KEY=your_openai_key

# ============================================
# OPTION 4: LM Studio (Local)
# ============================================
# LLM_PROVIDER=lmstudio
# LLM_MODEL=your-model-name
# LMSTUDIO_BASE_URL=http://localhost:1234/v1

# ============================================
# Common Settings (All Providers)
# ============================================
LOG_LEVEL=INFO
MAX_AUDIO_QUEUE_SIZE=50

# TTS Engine (unchanged regardless of LLM provider)
# TTS_ENGINE=kokoro  # Options: kokoro, orpheus, coqui
